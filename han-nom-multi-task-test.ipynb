{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c354383",
   "metadata": {},
   "source": [
    "# üß™ Multi-Task Model Testing Notebook - UPDATED! üî•\n",
    "\n",
    "Notebook n√†y d√πng ƒë·ªÉ test multi-task model (hierarchical classification + rotation prediction) tr√™n test dataset.\n",
    "\n",
    "## üì¶ Model hi·ªán t·∫°i:\n",
    "**Conditional Model with Rotation Detection**\n",
    "- Path: `models/conditional_model/1/best_model.pth`\n",
    "- Architecture: ResNet50 + CBAM\n",
    "- Tasks:\n",
    "  - ‚úÖ Hierarchical Classification (3 levels)\n",
    "  - ‚úÖ Rotation Detection (0¬∞, 90¬∞, 180¬∞, 270¬∞) - CH·ªà cho SinoNom\n",
    "- Training: Data augmentation x4 (m·ªói ·∫£nh SinoNom ‚Üí 4 samples)\n",
    "- Features:\n",
    "  - Multi-GPU training\n",
    "  - Mixed precision (AMP)\n",
    "  - Frozen backbone + trainable CBAM & heads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a372e26",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîÑ Changelog - Latest Updates\n",
    "\n",
    "### ‚úÖ **FIXED MODEL ARCHITECTURE MISMATCH** (Oct 30, 2025) üîß\n",
    "\n",
    "**Problem**: RuntimeError - Model architecture kh√¥ng kh·ªõp v·ªõi checkpoint!\n",
    "- Test notebook d√πng `MultiTaskResNet50` (simple CBAM)\n",
    "- Checkpoint trained v·ªõi `HierarchicalResNet50WithRotation` (advanced CBAM)\n",
    "\n",
    "**Solution**: C·∫≠p nh·∫≠t test notebook ƒë·ªÉ s·ª≠ d·ª•ng ƒê√öNG architecture:\n",
    "\n",
    "**1. CBAM Architecture** (‚úÖ Updated):\n",
    "```python\n",
    "# OLD (Simple CBAM):\n",
    "class ChannelAttention:\n",
    "    fc1 = nn.Conv2d(...)  # ‚ùå Missing in checkpoint\n",
    "    fc2 = nn.Conv2d(...)\n",
    "\n",
    "# NEW (Training notebook CBAM):\n",
    "class ChannelAttention:\n",
    "    shared_mlp = nn.Sequential(  # ‚úÖ Matches checkpoint\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(...),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(...)\n",
    "    )\n",
    "```\n",
    "\n",
    "**2. Model Architecture** (‚úÖ Updated):\n",
    "```python\n",
    "# OLD:\n",
    "class MultiTaskResNet50:\n",
    "    fc_main = nn.Linear(...)  # ‚ùå Missing in checkpoint\n",
    "    fc_doc = nn.Linear(...)\n",
    "    fc_text = nn.Linear(...)\n",
    "    fc_rotation = nn.Linear(...)\n",
    "\n",
    "# NEW:\n",
    "class HierarchicalResNet50WithRotation:\n",
    "    h1_layer = nn.Sequential(...)  # ‚úÖ Matches checkpoint\n",
    "    h2_layer = nn.Sequential(...)\n",
    "    h3_layer = nn.Sequential(...)\n",
    "    classifier1 = nn.Linear(...)\n",
    "    classifier2 = nn.Linear(...)\n",
    "    classifier3 = nn.Linear(...)\n",
    "    rotation_head = nn.Sequential(...)\n",
    "```\n",
    "\n",
    "**3. Output Format** (‚úÖ Updated):\n",
    "```python\n",
    "# OLD:\n",
    "outputs = [out_main, out_doc, out_text, out_rotation]\n",
    "\n",
    "# NEW:\n",
    "hierarchical_outputs, rotation_output = model(x)\n",
    "# hierarchical_outputs = [out_main, out_doc, out_text]\n",
    "# rotation_output = out_rotation\n",
    "```\n",
    "\n",
    "**Changes**:\n",
    "1. **Model Architecture**: `HierarchicalResNet50WithRotation` (‚úÖ matches training)\n",
    "2. **CBAM Implementation**: Advanced CBAM with `shared_mlp` and `ChannelPool`\n",
    "3. **Output Handling**: Tuple unpacking for hierarchical & rotation outputs\n",
    "4. **Model Loading**: Handle DataParallel wrapped models\n",
    "5. **Image Size**: 128x128 (unchanged)\n",
    "6. **Rotation Testing**: Enabled by default (`test_rotations=True`)\n",
    "\n",
    "**Expected Performance**:\n",
    "- Main Category Acc: ~95%+\n",
    "- Document Type Acc: ~98%+ (SinoNom only)\n",
    "- Text Direction Acc: ~99%+ (Thong_thuong only)\n",
    "- Rotation Acc: **80-90%** (SinoNom only, all 4 angles) ‚¨ÜÔ∏è\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1169d225",
   "metadata": {},
   "source": [
    "## üìö 1. Import libraries & Define Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a5c2c1",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Fix Numpy Version Issue\n",
    "\n",
    "**Problem**: \"Numpy is not available\" error khi ƒë·ªçc ·∫£nh\n",
    "- Numpy 2.x kh√¥ng t∆∞∆°ng th√≠ch v·ªõi Pillow c≈©\n",
    "- C·∫ßn downgrade v·ªÅ numpy < 2.0\n",
    "\n",
    "**Solution**: Run cell d∆∞·ªõi ƒë·ªÉ install numpy ƒë√∫ng version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41860e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy<2\n",
      "  Using cached numpy-1.26.4-cp39-cp39-macosx_10_9_x86_64.whl.metadata (61 kB)\n",
      "Using cached numpy-1.26.4-cp39-cp39-macosx_10_9_x86_64.whl (20.6 MB)\n",
      "Using cached numpy-1.26.4-cp39-cp39-macosx_10_9_x86_64.whl (20.6 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# ‚ö†Ô∏è FIX: Install numpy < 2.0 to fix \"Numpy is not available\" error\n",
    "# Numpy 2.x causes compatibility issues with Pillow when reading images\n",
    "!pip install 'numpy<2' --upgrade\n",
    "\n",
    "print(\"‚úÖ Numpy version fixed! Please RESTART KERNEL and run cells again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedd8e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Verify package versions\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üì¶ Package Versions\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Numpy version: {np.__version__}\")\n",
    "print(f\"Pillow version: {Image.__version__}\")\n",
    "\n",
    "# Check numpy version\n",
    "numpy_version = tuple(map(int, np.__version__.split('.')[:2]))\n",
    "if numpy_version >= (2, 0):\n",
    "    print(\"\\n‚ö†Ô∏è WARNING: Numpy 2.x detected!\")\n",
    "    print(\"   Please run the cell above to downgrade to numpy < 2.0\")\n",
    "    print(\"   Then RESTART KERNEL and run cells again.\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Numpy version OK: {np.__version__}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "764f37e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.2.2\n",
      "CUDA available: False\n",
      "üñ•Ô∏è Using device: cpu\n",
      "‚úÖ ƒê√£ import libraries v√† define constants th√†nh c√¥ng!\n"
     ]
    }
   ],
   "source": [
    "# ==================== IMPORT LIBRARIES ====================\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "from typing import Dict, Tuple, List, Optional, Union\n",
    "import io\n",
    "\n",
    "# Excel export\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.drawing.image import Image as XLImage\n",
    "from openpyxl.styles import Alignment, PatternFill, Font\n",
    "from openpyxl.utils import get_column_letter\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# ==================== DEFINE CONSTANTS ====================\n",
    "\n",
    "# Hierarchical class mappings\n",
    "MAIN_CATEGORIES = {\"SinoNom\": 0, \"NonSinoNom\": 1}\n",
    "DOC_TYPES = {\"Thong_thuong\": 0, \"Hanh_chinh\": 1, \"Ngoai_canh\": 2}\n",
    "TEXT_DIRECTIONS = {\"Doc\": 0, \"Ngang\": 1}\n",
    "\n",
    "# Rotation angles mapping\n",
    "ROTATION_ANGLES = {0: 0, 90: 1, 180: 2, 270: 3}\n",
    "\n",
    "# Reverse mappings for inference\n",
    "INV_MAIN_CATEGORIES = {v: k for k, v in MAIN_CATEGORIES.items()}\n",
    "INV_DOC_TYPES = {v: k for k, v in DOC_TYPES.items()}\n",
    "INV_TEXT_DIRECTIONS = {v: k for k, v in TEXT_DIRECTIONS.items()}\n",
    "INV_ROTATION_ANGLES = {v: k for k, v in ROTATION_ANGLES.items()}\n",
    "\n",
    "# Model configuration\n",
    "IMAGE_SIZE = (128, 128)  # ‚úÖ UPDATED: 128x128 for conditional model (was 224x224)\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "# Device configuration\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üñ•Ô∏è Using device: {DEVICE}\")\n",
    "\n",
    "# Paths\n",
    "OUTPUT_PATH = \"outputs\"\n",
    "TEST_PATH = \"test_full\"  # Th∆∞ m·ª•c ch·ª©a test data\n",
    "\n",
    "print(\"‚úÖ ƒê√£ import libraries v√† define constants th√†nh c√¥ng!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91d16c4",
   "metadata": {},
   "source": [
    "## üèóÔ∏è 2. Define CBAM Attention Mechanism & Multi-Task Model Architecture\n",
    "\n",
    "**‚ö†Ô∏è UPDATED**: Model architecture ph·∫£i KH·ªöP v·ªõi training notebook!\n",
    "\n",
    "**Model**: `HierarchicalResNet50WithRotation`\n",
    "- Architecture: ResNet50 backbone + CBAM attention\n",
    "- Features:\n",
    "  - **Deep Hierarchical Classification**: h1_layer ‚Üí h2_layer ‚Üí h3_layer v·ªõi feature concatenation\n",
    "  - **Rotation Detection Head**: Separate branch t·ª´ base features\n",
    "- Output format: `[hierarchical_outputs, rotation_output]`\n",
    "  - `hierarchical_outputs = [out_main, out_doc, out_text]`\n",
    "  - `rotation_output = out_rotation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3db69030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CBAM attention mechanism defined!\n",
      "‚úÖ HierarchicalResNet50WithRotation with CBAM architecture defined!\n"
     ]
    }
   ],
   "source": [
    "# ==================== CBAM ATTENTION MECHANISM ====================\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    \"\"\"Channel Attention in CBAM.\"\"\"\n",
    "    \n",
    "    def __init__(self, channel_in, reduction_ratio=16, pool_types=['avg', 'max']):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.pool_types = pool_types\n",
    "        \n",
    "        self.shared_mlp = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(channel_in, channel_in // reduction_ratio),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel_in // reduction_ratio, channel_in)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        channel_attentions = []\n",
    "        \n",
    "        for pool_type in self.pool_types:\n",
    "            if pool_type == 'avg':\n",
    "                pool_init = nn.AvgPool2d(kernel_size=(x.size(2), x.size(3)), \n",
    "                                       stride=(x.size(2), x.size(3)))\n",
    "                avg_pool = pool_init(x)\n",
    "                channel_attentions.append(self.shared_mlp(avg_pool))\n",
    "            elif pool_type == 'max':\n",
    "                pool_init = nn.MaxPool2d(kernel_size=(x.size(2), x.size(3)), \n",
    "                                       stride=(x.size(2), x.size(3)))\n",
    "                max_pool = pool_init(x)\n",
    "                channel_attentions.append(self.shared_mlp(max_pool))\n",
    "        \n",
    "        pooling_sums = torch.stack(channel_attentions, dim=0).sum(dim=0)\n",
    "        scaled = torch.sigmoid(pooling_sums).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
    "        \n",
    "        return x * scaled\n",
    "\n",
    "class ChannelPool(nn.Module):\n",
    "    \"\"\"Merge channels into 2 channels (max and mean).\"\"\"\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.cat((torch.max(x, 1)[0].unsqueeze(1), \n",
    "                         torch.mean(x, 1).unsqueeze(1)), dim=1)\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    \"\"\"Spatial Attention in CBAM.\"\"\"\n",
    "    \n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        \n",
    "        self.compress = ChannelPool()\n",
    "        self.spatial_attention = nn.Sequential(\n",
    "            nn.Conv2d(2, 1, kernel_size=kernel_size, stride=1, \n",
    "                     padding=(kernel_size-1)//2, bias=False),\n",
    "            nn.BatchNorm2d(1, eps=1e-5, momentum=0.01, affine=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_compress = self.compress(x)\n",
    "        x_output = self.spatial_attention(x_compress)\n",
    "        scaled = torch.sigmoid(x_output)\n",
    "        return x * scaled\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    \"\"\"Convolutional Block Attention Module.\"\"\"\n",
    "    \n",
    "    def __init__(self, channel_in, reduction_ratio=16, pool_types=['avg', 'max'], spatial=True):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.spatial = spatial\n",
    "        \n",
    "        self.channel_attention = ChannelAttention(channel_in, reduction_ratio, pool_types)\n",
    "        \n",
    "        if self.spatial:\n",
    "            self.spatial_attention = SpatialAttention(kernel_size=7)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_out = self.channel_attention(x)\n",
    "        if self.spatial:\n",
    "            x_out = self.spatial_attention(x_out)\n",
    "        return x_out\n",
    "\n",
    "print(\"‚úÖ CBAM attention mechanism defined!\")\n",
    "\n",
    "# ==================== BOTTLENECK BLOCK & MULTI-TASK RESNET50 ====================\n",
    "\n",
    "class BottleneckCBAM(nn.Module):\n",
    "    \"\"\"Bottleneck block with CBAM attention.\"\"\"\n",
    "    expansion = 4\n",
    "    \n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, use_cbam=True):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.use_cbam = use_cbam\n",
    "        self.cbam = CBAM(planes * self.expansion) if use_cbam else None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        \n",
    "        if self.cbam:\n",
    "            out = self.cbam(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        \n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class HierarchicalResNet50WithRotation(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet50 with CBAM + Deep Hierarchical Classification + Rotation Detection.\n",
    "    \n",
    "    Multi-task learning:\n",
    "    - Shared backbone for feature extraction\n",
    "    - Hierarchical classification head (3 levels)\n",
    "    - Rotation detection head (4 classes: 0¬∞, 90¬∞, 180¬∞, 270¬∞)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, use_cbam=True, image_depth=3, num_classes=[2, 3, 2],\n",
    "                 enable_rotation=True, num_rotation_classes=4):\n",
    "        super().__init__()\n",
    "        self.expansion = 4\n",
    "        self.use_cbam = use_cbam\n",
    "        self.enable_rotation = enable_rotation\n",
    "        self.inplanes = 64\n",
    "        \n",
    "        # ==================== SHARED BACKBONE ====================\n",
    "        self.conv1 = nn.Conv2d(image_depth, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.layer1 = self._make_layer(BottleneckCBAM, 64, 3, use_cbam=use_cbam)\n",
    "        self.layer2 = self._make_layer(BottleneckCBAM, 128, 4, stride=2, use_cbam=use_cbam)\n",
    "        self.layer3 = self._make_layer(BottleneckCBAM, 256, 6, stride=2, use_cbam=use_cbam)\n",
    "        self.layer4 = self._make_layer(BottleneckCBAM, 512, 3, stride=2, use_cbam=use_cbam)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        # ==================== HIERARCHICAL CLASSIFICATION HEAD ====================\n",
    "        base_feature_dim = 512 * self.expansion  # 2048\n",
    "        \n",
    "        # Level 1: Main category (SinoNom/NonSinoNom)\n",
    "        self.h1_layer = nn.Sequential(\n",
    "            nn.Linear(base_feature_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "        # Level 2: Document type (depends on h1)\n",
    "        self.h2_layer = nn.Sequential(\n",
    "            nn.Linear(base_feature_dim + 512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.4)\n",
    "        )\n",
    "        \n",
    "        # Level 3: Text direction (depends on h1 + h2)\n",
    "        self.h3_layer = nn.Sequential(\n",
    "            nn.Linear(base_feature_dim + 512 + 256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        # Classification heads\n",
    "        self.classifier1 = nn.Linear(512, num_classes[0])  # Main category\n",
    "        self.classifier2 = nn.Linear(256, num_classes[1])  # Document type\n",
    "        self.classifier3 = nn.Linear(128, num_classes[2])  # Text direction\n",
    "        \n",
    "        # ==================== ROTATION DETECTION HEAD ====================\n",
    "        if self.enable_rotation:\n",
    "            self.rotation_head = nn.Sequential(\n",
    "                nn.Linear(base_feature_dim, 512),\n",
    "                nn.BatchNorm1d(512),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(512, 256),\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(256, num_rotation_classes)\n",
    "            )\n",
    "        \n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _make_layer(self, block, planes, blocks, stride=1, use_cbam=True):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, use_cbam=use_cbam))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, use_cbam=use_cbam))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # ==================== SHARED BACKBONE ====================\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        base_features = torch.flatten(x, 1)  # [batch, 2048]\n",
    "        \n",
    "        # ==================== HIERARCHICAL CLASSIFICATION ====================\n",
    "        # Level 1\n",
    "        h1 = self.h1_layer(base_features)  # [batch, 512]\n",
    "        out_main = self.classifier1(h1)\n",
    "        \n",
    "        # Level 2\n",
    "        h2_input = torch.cat([base_features, h1], dim=1)\n",
    "        h2 = self.h2_layer(h2_input)  # [batch, 256]\n",
    "        out_doc = self.classifier2(h2)\n",
    "        \n",
    "        # Level 3\n",
    "        h3_input = torch.cat([base_features, h1, h2], dim=1)\n",
    "        h3 = self.h3_layer(h3_input)  # [batch, 128]\n",
    "        out_text = self.classifier3(h3)\n",
    "        \n",
    "        # ==================== ROTATION DETECTION ====================\n",
    "        if self.enable_rotation:\n",
    "            out_rotation = self.rotation_head(base_features)\n",
    "            return [out_main, out_doc, out_text], out_rotation\n",
    "        else:\n",
    "            return [out_main, out_doc, out_text]\n",
    "\n",
    "print(\"‚úÖ HierarchicalResNet50WithRotation with CBAM architecture defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d219ea3b",
   "metadata": {},
   "source": [
    "## üîß 3. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da4e7331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Helper functions defined!\n"
     ]
    }
   ],
   "source": [
    "def load_multi_task_model(model_path, device=DEVICE):\n",
    "    \"\"\"\n",
    "    Load trained multi-task model t·ª´ checkpoint.\n",
    "    \"\"\"\n",
    "    print(f\"üìÇ Loading model from {model_path}...\")\n",
    "    \n",
    "    # Create model instance - s·ª≠ d·ª•ng HierarchicalResNet50WithRotation v·ªõi CBAM\n",
    "    model = HierarchicalResNet50WithRotation(\n",
    "        use_cbam=True,\n",
    "        image_depth=3,\n",
    "        num_classes=[2, 3, 2],  # [main_category, doc_type, text_direction]\n",
    "        enable_rotation=True,\n",
    "        num_rotation_classes=4\n",
    "    )\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    \n",
    "    # Load model state - handle both wrapped and unwrapped models\n",
    "    if 'model_state_dict' in checkpoint:\n",
    "        state_dict = checkpoint['model_state_dict']\n",
    "    else:\n",
    "        state_dict = checkpoint\n",
    "    \n",
    "    # Handle DataParallel wrapped models (remove 'module.' prefix)\n",
    "    if list(state_dict.keys())[0].startswith('module.'):\n",
    "        state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
    "    \n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Print model info\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"‚úÖ Model loaded successfully!\")\n",
    "    print(f\"   üìä Total parameters: {total_params:,}\")\n",
    "    print(f\"   üèãÔ∏è Trainable parameters: {trainable_params:,}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    \"\"\"\n",
    "    Xoay ·∫£nh theo g√≥c ch·ªâ ƒë·ªãnh.\n",
    "    \"\"\"\n",
    "    if angle == 0:\n",
    "        return image\n",
    "    elif angle == 90:\n",
    "        return image.rotate(90, expand=True)\n",
    "    elif angle == 180:\n",
    "        return image.rotate(180, expand=True)\n",
    "    elif angle == 270:\n",
    "        return image.rotate(270, expand=True)\n",
    "    else:\n",
    "        return image\n",
    "\n",
    "def filter_valid_labels(true_labels, pred_labels, valid_set):\n",
    "    \"\"\"\n",
    "    L·ªçc c√°c labels h·ª£p l·ªá ƒë·ªÉ t√≠nh confusion matrix.\n",
    "    \"\"\"\n",
    "    filtered_true = []\n",
    "    filtered_pred = []\n",
    "    \n",
    "    for t, p in zip(true_labels, pred_labels):\n",
    "        if t in valid_set and p in valid_set:\n",
    "            filtered_true.append(t)\n",
    "            filtered_pred.append(p)\n",
    "    \n",
    "    return filtered_true, filtered_pred\n",
    "\n",
    "print(\"‚úÖ Helper functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c1bc83",
   "metadata": {},
   "source": [
    "## üß™ 4. Main Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacb4f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Evaluation function defined!\n"
     ]
    }
   ],
   "source": [
    "def evaluate_multi_task_model(model_path, test_folder=\"test_full\", output_path=\"outputs\", test_rotations=False):\n",
    "    \"\"\"\n",
    "    ƒê√°nh gi√° multi-task model tr√™n test dataset.\n",
    "    \n",
    "    Args:\n",
    "        model_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file checkpoint model\n",
    "        test_folder: Th∆∞ m·ª•c ch·ª©a test data\n",
    "        output_path: Th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£\n",
    "        test_rotations: N·∫øu True, test model v·ªõi c√°c g√≥c xoay kh√°c nhau\n",
    "    \"\"\"\n",
    "    print(\"üöÄ Starting multi-task model evaluation...\")\n",
    "    \n",
    "    # Load model\n",
    "    model = load_multi_task_model(model_path)\n",
    "    \n",
    "    # Prepare transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Create Excel workbook\n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"Multi-Task Test Results\"\n",
    "    \n",
    "    # Set up headers\n",
    "    headers = [\n",
    "        \"Image\", \"File Name\", \n",
    "        \"Main Category\", \"Main Conf\",\n",
    "        \"Doc Type\", \"Doc Conf\",\n",
    "        \"Text Direction\", \"Text Conf\",\n",
    "        \"Rotation (deg)\", \"Rotation Conf\"\n",
    "    ]\n",
    "    \n",
    "    header_font = Font(size=14, bold=True)\n",
    "    cell_font = Font(size=12)\n",
    "    \n",
    "    for col, header in enumerate(headers, 1):\n",
    "        cell = ws.cell(row=1, column=col, value=header)\n",
    "        cell.font = header_font\n",
    "        cell.fill = PatternFill(\"solid\", fgColor=\"CCCCCC\")\n",
    "        cell.alignment = Alignment(horizontal='center', vertical='center', wrap_text=True)\n",
    "    \n",
    "    # Set column widths\n",
    "    ws.column_dimensions['A'].width = 60  # Image\n",
    "    ws.column_dimensions['B'].width = 50  # Filename\n",
    "    for col in range(3, len(headers) + 1):\n",
    "        ws.column_dimensions[get_column_letter(col)].width = 18\n",
    "    \n",
    "    # Initialize lists for metrics\n",
    "    true_main = []\n",
    "    pred_main = []\n",
    "    true_doc = []\n",
    "    pred_doc = []\n",
    "    true_text = []\n",
    "    pred_text = []\n",
    "    true_rotation = []\n",
    "    pred_rotation = []\n",
    "    \n",
    "    # Collect test files\n",
    "    test_files = []\n",
    "    img_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.avif', '.jfif', '.webp']\n",
    "    \n",
    "    for root, _, files in os.walk(test_folder):\n",
    "        for file in files:\n",
    "            if any(file.lower().endswith(ext) for ext in img_extensions):\n",
    "                test_files.append(os.path.join(root, file))\n",
    "    \n",
    "    print(f\"Found {len(test_files)} images to process...\")\n",
    "    \n",
    "    # Determine rotation angles to test\n",
    "    rotation_angles_to_test = [0, 90, 180, 270] if test_rotations else [0]\n",
    "    \n",
    "    # Process each image\n",
    "    row = 2\n",
    "    \n",
    "    for img_path in tqdm(test_files, desc=\"Processing images\"):\n",
    "        try:\n",
    "            # Get true labels from folder structure\n",
    "            rel_path = os.path.relpath(img_path, test_folder)\n",
    "            path_parts = rel_path.split(os.sep)\n",
    "            \n",
    "            # Extract true labels\n",
    "            true_main_cat = path_parts[0]\n",
    "            true_doc_type = path_parts[1] if len(path_parts) > 1 else \"N/A\"\n",
    "            true_text_dir = path_parts[2] if len(path_parts) > 2 else \"N/A\"\n",
    "            \n",
    "            # Load original image - handle various formats\n",
    "            try:\n",
    "                img = Image.open(img_path)\n",
    "                # Convert to RGB immediately to avoid numpy issues\n",
    "                if img.mode != 'RGB':\n",
    "                    img = img.convert('RGB')\n",
    "            except Exception as img_error:\n",
    "                print(f\"‚ö†Ô∏è Cannot read image {img_path}: {img_error}\")\n",
    "                continue\n",
    "            \n",
    "            # Test with different rotation angles\n",
    "            for true_rot_angle in rotation_angles_to_test:\n",
    "                # Rotate image\n",
    "                rotated_img = rotate_image(img.copy(), true_rot_angle)\n",
    "                \n",
    "                # Transform and predict\n",
    "                tensor = transform(rotated_img).unsqueeze(0).to(DEVICE)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    # Model returns: [hierarchical_outputs, rotation_output]\n",
    "                    # hierarchical_outputs = [out_main, out_doc, out_text]\n",
    "                    hierarchical_outputs, rotation_output = model(tensor)\n",
    "                    \n",
    "                    # Process hierarchical classification outputs\n",
    "                    hier_probs = [F.softmax(out, dim=1).squeeze(0).cpu().numpy() for out in hierarchical_outputs]\n",
    "                    hier_preds = [int(np.argmax(p)) for p in hier_probs]\n",
    "                    hier_confs = [float(np.max(p)) for p in hier_probs]\n",
    "                    \n",
    "                    # Process rotation output\n",
    "                    rot_probs = F.softmax(rotation_output, dim=1).squeeze(0).cpu().numpy()\n",
    "                    rot_pred = int(np.argmax(rot_probs))\n",
    "                    rot_conf = float(np.max(rot_probs))\n",
    "                \n",
    "                # Convert predictions to labels\n",
    "                pred_main_cat = INV_MAIN_CATEGORIES.get(hier_preds[0], str(hier_preds[0]))\n",
    "                pred_doc_type = \"N/A\"\n",
    "                pred_text_dir = \"N/A\"\n",
    "                doc_conf = 1.0\n",
    "                text_conf = 1.0\n",
    "                \n",
    "                if hier_preds[0] == MAIN_CATEGORIES[\"SinoNom\"]:\n",
    "                    pred_doc_type = INV_DOC_TYPES.get(hier_preds[1], str(hier_preds[1]))\n",
    "                    doc_conf = hier_confs[1]\n",
    "                    if hier_preds[1] == DOC_TYPES[\"Thong_thuong\"]:\n",
    "                        pred_text_dir = INV_TEXT_DIRECTIONS.get(hier_preds[2], str(hier_preds[2]))\n",
    "                        text_conf = hier_confs[2]\n",
    "                \n",
    "                pred_rot_angle = INV_ROTATION_ANGLES.get(rot_pred, 0)\n",
    "                \n",
    "                # Add to confusion matrix lists\n",
    "                true_main.append(true_main_cat)\n",
    "                pred_main.append(pred_main_cat)\n",
    "                \n",
    "                if true_doc_type != \"N/A\" and pred_doc_type != \"N/A\":\n",
    "                    true_doc.append(true_doc_type)\n",
    "                    pred_doc.append(pred_doc_type)\n",
    "                \n",
    "                if true_text_dir != \"N/A\" and pred_text_dir != \"N/A\":\n",
    "                    true_text.append(true_text_dir)\n",
    "                    pred_text.append(pred_text_dir)\n",
    "                \n",
    "                true_rotation.append(str(true_rot_angle))\n",
    "                pred_rotation.append(str(pred_rot_angle))\n",
    "                \n",
    "                # Add row to Excel\n",
    "                try:\n",
    "                    img_thumb = rotated_img.copy()\n",
    "                    img_thumb.thumbnail((300, 300))\n",
    "                    img_buffer = io.BytesIO()\n",
    "                    # Save as PNG to avoid format issues\n",
    "                    img_thumb.save(img_buffer, format='PNG')\n",
    "                    xl_image = XLImage(img_buffer)\n",
    "                    \n",
    "                    ws.row_dimensions[row].height = 225\n",
    "                    xl_image.anchor = f'A{row}'\n",
    "                    ws.add_image(xl_image)\n",
    "                except Exception as thumb_error:\n",
    "                    print(f\"‚ö†Ô∏è Cannot create thumbnail for {img_path}: {thumb_error}\")\n",
    "                    # Leave image cell empty if thumbnail fails\n",
    "                \n",
    "                # Add data\n",
    "                filename = f\"{os.path.basename(img_path)} (rot={true_rot_angle}¬∞)\"\n",
    "                data_values = [\n",
    "                    filename,\n",
    "                    pred_main_cat, f\"{hier_confs[0]:.3f}\",\n",
    "                    pred_doc_type, f\"{doc_conf:.3f}\",\n",
    "                    pred_text_dir, f\"{text_conf:.3f}\",\n",
    "                    f\"{pred_rot_angle}¬∞\", f\"{rot_conf:.3f}\"\n",
    "                ]\n",
    "                \n",
    "                for col, value in enumerate(data_values, 2):\n",
    "                    cell = ws.cell(row=row, column=col, value=value)\n",
    "                    cell.font = cell_font\n",
    "                    cell.alignment = Alignment(horizontal='center', vertical='center')\n",
    "                \n",
    "                row += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "    \n",
    "    # Filter valid labels for confusion matrices\n",
    "    if true_doc:\n",
    "        true_doc, pred_doc = filter_valid_labels(\n",
    "            true_doc, pred_doc, \n",
    "            {\"Ngoai_canh\", \"Thong_thuong\", \"Hanh_chinh\"}\n",
    "        )\n",
    "    \n",
    "    if true_text:\n",
    "        true_text, pred_text = filter_valid_labels(\n",
    "            true_text, pred_text,\n",
    "            {\"Doc\", \"Ngang\"}\n",
    "        )\n",
    "    \n",
    "    # Print classification reports\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä CLASSIFICATION REPORTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\\nüè∑Ô∏è Main Category:\")\n",
    "    print(classification_report(true_main, pred_main, digits=4))\n",
    "    print(f\"Accuracy: {accuracy_score(true_main, pred_main):.4f}\")\n",
    "    \n",
    "    if true_doc:\n",
    "        print(\"\\nüìã Document Type:\")\n",
    "        print(classification_report(true_doc, pred_doc, digits=4))\n",
    "        print(f\"Accuracy: {accuracy_score(true_doc, pred_doc):.4f}\")\n",
    "    \n",
    "    if true_text:\n",
    "        print(\"\\nüìê Text Direction:\")\n",
    "        print(classification_report(true_text, pred_text, digits=4))\n",
    "        print(f\"Accuracy: {accuracy_score(true_text, pred_text):.4f}\")\n",
    "    \n",
    "    print(\"\\nüîÑ Rotation Angle:\")\n",
    "    print(classification_report(true_rotation, pred_rotation, digits=4))\n",
    "    print(f\"Accuracy: {accuracy_score(true_rotation, pred_rotation):.4f}\")\n",
    "    \n",
    "    # Create confusion matrices\n",
    "    num_plots = 4 if (true_doc and true_text) else 3 if true_doc else 2\n",
    "    fig, axes = plt.subplots(1, num_plots, figsize=(6*num_plots, 5))\n",
    "    \n",
    "    if num_plots == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    plot_idx = 0\n",
    "    \n",
    "    # Main category\n",
    "    cm_main = confusion_matrix(true_main, pred_main)\n",
    "    sns.heatmap(cm_main, annot=True, fmt='d',\n",
    "                xticklabels=sorted(set(true_main)),\n",
    "                yticklabels=sorted(set(true_main)),\n",
    "                cmap='Blues', ax=axes[plot_idx], square=True,\n",
    "                cbar_kws={'label': 'Count'})\n",
    "    axes[plot_idx].set_title('Main Category', fontsize=12, pad=10)\n",
    "    axes[plot_idx].set_xlabel('Predicted', fontsize=10)\n",
    "    axes[plot_idx].set_ylabel('True', fontsize=10)\n",
    "    plot_idx += 1\n",
    "    \n",
    "    # Document type\n",
    "    if true_doc:\n",
    "        cm_doc = confusion_matrix(true_doc, pred_doc)\n",
    "        sns.heatmap(cm_doc, annot=True, fmt='d',\n",
    "                    xticklabels=sorted(set(true_doc)),\n",
    "                    yticklabels=sorted(set(true_doc)),\n",
    "                    cmap='Blues', ax=axes[plot_idx], square=True,\n",
    "                    cbar_kws={'label': 'Count'})\n",
    "        axes[plot_idx].set_title('Document Type', fontsize=12, pad=10)\n",
    "        axes[plot_idx].set_xlabel('Predicted', fontsize=10)\n",
    "        axes[plot_idx].set_ylabel('True', fontsize=10)\n",
    "        plot_idx += 1\n",
    "    \n",
    "    # Text direction\n",
    "    if true_text:\n",
    "        cm_text = confusion_matrix(true_text, pred_text)\n",
    "        sns.heatmap(cm_text, annot=True, fmt='d',\n",
    "                    xticklabels=sorted(set(true_text)),\n",
    "                    yticklabels=sorted(set(true_text)),\n",
    "                    cmap='Blues', ax=axes[plot_idx], square=True,\n",
    "                    cbar_kws={'label': 'Count'})\n",
    "        axes[plot_idx].set_title('Text Direction', fontsize=12, pad=10)\n",
    "        axes[plot_idx].set_xlabel('Predicted', fontsize=10)\n",
    "        axes[plot_idx].set_ylabel('True', fontsize=10)\n",
    "        plot_idx += 1\n",
    "    \n",
    "    # Rotation\n",
    "    cm_rotation = confusion_matrix(true_rotation, pred_rotation)\n",
    "    sns.heatmap(cm_rotation, annot=True, fmt='d',\n",
    "                xticklabels=sorted(set(true_rotation), key=lambda x: int(x)),\n",
    "                yticklabels=sorted(set(true_rotation), key=lambda x: int(x)),\n",
    "                cmap='Blues', ax=axes[plot_idx], square=True,\n",
    "                cbar_kws={'label': 'Count'})\n",
    "    axes[plot_idx].set_title('Rotation Angle', fontsize=12, pad=10)\n",
    "    axes[plot_idx].set_xlabel('Predicted', fontsize=10)\n",
    "    axes[plot_idx].set_ylabel('True', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout(pad=3.0)\n",
    "    \n",
    "    # Save results\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    # Save confusion matrices\n",
    "    plt.savefig(os.path.join(output_path, f'multi_task_confusion_matrices_{timestamp}.png'),\n",
    "                dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "    \n",
    "    # Save Excel file\n",
    "    excel_path = os.path.join(output_path, f'multi_task_test_results_{timestamp}.xlsx')\n",
    "    wb.save(excel_path)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Evaluation complete!\")\n",
    "    print(f\"üìä Results saved to {excel_path}\")\n",
    "    print(f\"üìà Confusion matrices saved to {output_path}/multi_task_confusion_matrices_{timestamp}.png\")\n",
    "\n",
    "print(\"‚úÖ Evaluation function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e44e602",
   "metadata": {},
   "source": [
    "## üöÄ 5. Run Evaluation - Conditional Model\n",
    "\n",
    "**Model**: `models/conditional_model/1/best_model.pth`\n",
    "\n",
    "**C·∫•u h√¨nh**:\n",
    "- ‚úÖ `test_rotations=True`: Test v·ªõi T·∫§T C·∫¢ 4 g√≥c xoay (0¬∞, 90¬∞, 180¬∞, 270¬∞)\n",
    "- Dataset: `test_full/` \n",
    "- Output: Excel file v·ªõi predictions v√† confidence scores\n",
    "\n",
    "**K·∫øt qu·∫£ s·∫Ω bao g·ªìm**:\n",
    "1. Main Category (SinoNom/NonSinoNom)\n",
    "2. Document Type (Thong_thuong/Hanh_chinh/Ngoai_canh) - CH·ªà cho SinoNom\n",
    "3. Text Direction (Doc/Ngang) - CH·ªà cho Thong_thuong\n",
    "4. Rotation Angle (0¬∞/90¬∞/180¬∞/270¬∞) - CH·ªà cho SinoNom\n",
    "\n",
    "Ch·∫°y ƒë√°nh gi√° model tr√™n test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbe2738b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üîç Verification\n",
      "======================================================================\n",
      "‚úÖ Model file found: models/conditional_model/1/best_model.pth\n",
      "   Size: 156.39 MB\n",
      "\n",
      "‚úÖ Test dataset found: test_full\n",
      "   Total test images: 625\n",
      "\n",
      "‚úÖ Output directory exists: outputs\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Verify model path v√† dataset\n",
    "import os\n",
    "\n",
    "MODEL_PATH = \"models/conditional_model/1/best_model.pth\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üîç Verification\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check model file\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    model_size = os.path.getsize(MODEL_PATH) / (1024**2)  # Convert to MB\n",
    "    print(f\"‚úÖ Model file found: {MODEL_PATH}\")\n",
    "    print(f\"   Size: {model_size:.2f} MB\")\n",
    "else:\n",
    "    print(f\"‚ùå Model NOT found: {MODEL_PATH}\")\n",
    "    print(\"   Available models:\")\n",
    "    if os.path.exists(\"models/conditional_model/1/\"):\n",
    "        for f in os.listdir(\"models/conditional_model/1/\"):\n",
    "            print(f\"   - {f}\")\n",
    "\n",
    "# Check test dataset\n",
    "if os.path.exists(TEST_PATH):\n",
    "    print(f\"\\n‚úÖ Test dataset found: {TEST_PATH}\")\n",
    "    # Count test images\n",
    "    total_images = 0\n",
    "    for root, dirs, files in os.walk(TEST_PATH):\n",
    "        total_images += len([f for f in files if f.lower().endswith(('.jpg', '.jpeg', '.png', '.avif', '.jfif'))])\n",
    "    print(f\"   Total test images: {total_images}\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå Test dataset NOT found: {TEST_PATH}\")\n",
    "\n",
    "# Check output directory\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)\n",
    "    print(f\"\\nüìÅ Created output directory: {OUTPUT_PATH}\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Output directory exists: {OUTPUT_PATH}\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94c1f0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting multi-task model evaluation...\n",
      "üìÇ Loading model from models/conditional_model/1/best_model.pth...\n",
      "‚úÖ Model loaded successfully!\n",
      "   üìä Total parameters: 29,292,731\n",
      "   üèãÔ∏è Trainable parameters: 29,292,731\n",
      "Found 645 images to process...\n",
      "‚úÖ Model loaded successfully!\n",
      "   üìä Total parameters: 29,292,731\n",
      "   üèãÔ∏è Trainable parameters: 29,292,731\n",
      "Found 645 images to process...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   1%|          | 7/645 [00:00<00:10, 61.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing test_full/NonSinoNom/non_sino_nom_021.webp: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_032.jpeg: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_033.jpg: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_027.jpg: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_026.jpg: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_049.jpeg: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_030.png: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_024.png: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_025.jpg: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_019.jpg: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_019.jpg: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_031.png: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_031.png: Numpy is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   3%|‚ñé         | 17/645 [00:01<01:03,  9.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing test_full/NonSinoNom/non_sino_nom_009.jpg: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_008.jpg: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_020.jpg: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_022.jpg: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_023.jpg: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_044.png: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_043.jpeg: Numpy is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   3%|‚ñé         | 20/645 [00:01<01:01, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing test_full/NonSinoNom/non_sino_nom_014.jpeg: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_045.png: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_047.png: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_034.jpeg: Numpy is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   6%|‚ñå         | 38/645 [00:02<00:21, 28.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing test_full/NonSinoNom/non_sino_nom_046.png: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_018.jpeg: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_035.jpeg: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_006.webp: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_042.jpeg: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_039.jpeg: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_005.webp: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_041.jpeg: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_036.jpeg: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_037.jpeg: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_048.jpg: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_040.jpeg: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_004.webp: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_012.jpg: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_007.jpg: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_013.jpg: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_003.webp: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_011.jpg: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_051.jpeg: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_010.jpg: Numpy is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   7%|‚ñã         | 45/645 [00:02<00:19, 30.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing test_full/NonSinoNom/non_sino_nom_038.jpg: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_028.png: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_050.jpeg: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_015.jpg: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_001.jpg: Numpy is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   9%|‚ñâ         | 60/645 [00:02<00:15, 37.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing test_full/NonSinoNom/non_sino_nom_029.png: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_002.jpg: Numpy is not available\n",
      "Error processing test_full/NonSinoNom/non_sino_nom_016.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Hanh_chinh/hanh_chinh_010.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Hanh_chinh/hanh_chinh_019.jpeg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Hanh_chinh/hanh_chinh_007.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Hanh_chinh/hanh_chinh_003.jpeg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Hanh_chinh/hanh_chinh_012.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Hanh_chinh/hanh_chinh_016.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Hanh_chinh/hanh_chinh_002.jpeg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Hanh_chinh/hanh_chinh_011.webp: Numpy is not available\n",
      "Error processing test_full/SinoNom/Hanh_chinh/hanh_chinh_001.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Hanh_chinh/hanh_chinh_015.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Hanh_chinh/hanh_chinh_018.jpeg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Hanh_chinh/hanh_chinh_014.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Hanh_chinh/hanh_chinh_004.jpeg: Numpy is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  12%|‚ñà‚ñè        | 77/645 [00:03<00:11, 49.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing test_full/SinoNom/Hanh_chinh/hanh_chinh_017.webp: Numpy is not available\n",
      "Error processing test_full/SinoNom/Hanh_chinh/hanh_chinh_011.jpeg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Hanh_chinh/hanh_chinh_006.jpeg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Hanh_chinh/hanh_chiÃÅnh_022.jpeg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Hanh_chinh/hanh_chinh_021.jpeg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Hanh_chinh/hanh_chinh_023.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Hanh_chinh/hanh_chinh_013.webp: Numpy is not available\n",
      "Error processing test_full/SinoNom/Hanh_chinh/hanh_chinh_005.webp: Numpy is not available\n",
      "Error processing test_full/SinoNom/Hanh_chinh/hanh_chinh_020.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Hanh_chinh/hanh_chinh_008.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Hanh_chinh/hanh_chinh_009.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_092.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_385.jpeg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/thong_thuong_ngang_036.jpeg: Numpy is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  13%|‚ñà‚ñé        | 84/645 [00:03<00:11, 50.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_444.jpeg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_737.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_904.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/thong_thuong_ngang_020.jpeg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_1610.JPG: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_131.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/thong_thuong_ngang_005.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/thong_thuong_ngang_011.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_1374.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_1162.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/thong_thuong_ngang_010.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_1349.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_1349.jpg: Numpy is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  14%|‚ñà‚ñç        | 90/645 [00:03<00:21, 25.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_695.jpg: Numpy is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  15%|‚ñà‚ñç        | 95/645 [00:04<00:24, 22.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_1407.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/han_ngang08 (4).jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_497.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_124.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_087.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_291.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_720.png: Numpy is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  16%|‚ñà‚ñå        | 103/645 [00:04<00:21, 25.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/thong_thuong_ngang_006.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_1439.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_683.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_668.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_1175.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/thong_thuong_ngang_012.PNG: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_1438.jpg: Numpy is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  18%|‚ñà‚ñä        | 114/645 [00:04<00:18, 27.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_696.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_1389.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_523.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_721.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_1014.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/thong_thuong_ngang_041.jpeg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_1766.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_090.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_1010.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_731.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/thong_thuong_ngang_040.jpeg: Numpy is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  18%|‚ñà‚ñä        | 118/645 [00:05<00:25, 20.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_490.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/thong_thuong_ngang_017.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/thong_thuong_ngang_003.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_686.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_335.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_1428.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_645.jpg: Numpy is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  20%|‚ñà‚ñâ        | 126/645 [00:05<00:25, 20.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_678.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_1603.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_1165.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/thong_thuong_ngang_002.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_122.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/thong_thuong_ngang_016.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_297.png: Numpy is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  20%|‚ñà‚ñà        | 130/645 [00:05<00:30, 16.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_724.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_1211.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_732.png: Numpy is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  22%|‚ñà‚ñà‚ñè       | 140/645 [00:06<00:24, 20.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_1013.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_1007.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_901.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_518.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/thong_thuong_ngang_014.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_120.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_691.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_1198.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/thong_thuong_ngang_028.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_1167.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/thong_thuong_ngang_029.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_1675.jpeg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_492.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_860.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_1364.png: Numpy is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  23%|‚ñà‚ñà‚ñé       | 148/645 [00:06<00:22, 21.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_1172.jpg: Numpy is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  24%|‚ñà‚ñà‚ñé       | 152/645 [00:07<00:28, 17.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_1628.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/thong_thuong_ngang_015.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_653.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/thong_thuong_ngang_001.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_928.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_727.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_224.png: Numpy is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  24%|‚ñà‚ñà‚ñç       | 156/645 [00:07<00:30, 16.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_032.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_754.png: Numpy is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  25%|‚ñà‚ñà‚ñå       | 162/645 [00:07<00:29, 16.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_218.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_973.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_556.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_1115.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/thong_thuong_ngang_066.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_1296.jpeg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_620.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_378.jpg: Numpy is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  26%|‚ñà‚ñà‚ñå       | 167/645 [00:07<00:24, 19.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_185.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_1101.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/thong_thuong_ngang_072.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_387.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_153.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_1128.PNG: Numpy is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  27%|‚ñà‚ñà‚ñã       | 172/645 [00:08<00:26, 17.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_609.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_351.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_379.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/thong_thuong_ngang_073.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_635.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/thong_thuong_ngang_051.jpeg: Numpy is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  28%|‚ñà‚ñà‚ñä       | 178/645 [00:08<00:25, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_225.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_543.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_543.jpg: Numpy is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  29%|‚ñà‚ñà‚ñâ       | 186/645 [00:09<00:29, 15.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_231.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_966.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_594.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_999.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/thong_thuong_ngang_047.jpeg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_755.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_769.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_782.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/thong_thuong_ngang_067.jpeg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_782.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/thong_thuong_ngang_067.jpeg: Numpy is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  29%|‚ñà‚ñà‚ñâ       | 189/645 [00:09<00:38, 11.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_964.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_970.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_233.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_757.jpg: Numpy is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  30%|‚ñà‚ñà‚ñâ       | 193/645 [00:10<00:37, 11.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_582.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_958.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_1102.jpg: Numpy is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  31%|‚ñà‚ñà‚ñà       | 200/645 [00:10<00:23, 19.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_1314.jpg: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_409.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/thong_thuong_ngang_071.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/ngang_390.png: Numpy is not available\n",
      "Error processing test_full/SinoNom/Thong_thuong/Ngang/thong_thuong_ngang_070.png: Numpy is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m MODEL_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/conditional_model/1/best_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Conditional model with rotation detection\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Ch·∫°y evaluation\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# test_rotations=False: ch·ªâ test v·ªõi g√≥c xoay 0 ƒë·ªô (·∫£nh g·ªëc)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# test_rotations=True: test v·ªõi c√°c g√≥c xoay 0, 90, 180, 270 ƒë·ªô\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mevaluate_multi_task_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTEST_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOUTPUT_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_rotations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# ‚úÖ Enable rotation testing cho conditional model\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 91\u001b[0m, in \u001b[0;36mevaluate_multi_task_model\u001b[0;34m(model_path, test_folder, output_path, test_rotations)\u001b[0m\n\u001b[1;32m     88\u001b[0m true_text_dir \u001b[38;5;241m=\u001b[39m path_parts[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(path_parts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN/A\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Load original image\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Test with different rotation angles\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m true_rot_angle \u001b[38;5;129;01min\u001b[39;00m rotation_angles_to_test:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# Rotate image\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Luan_van/source_code/Han_nom_NC_TT_HC_model1/.venv/lib/python3.9/site-packages/PIL/Image.py:986\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;15\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;16\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;24\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    984\u001b[0m     deprecate(mode, \u001b[38;5;241m12\u001b[39m)\n\u001b[0;32m--> 986\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Luan_van/source_code/Han_nom_NC_TT_HC_model1/.venv/lib/python3.9/site-packages/PIL/ImageFile.py:335\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m):\n\u001b[1;32m    333\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 335\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_prepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m err_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m  \u001b[38;5;66;03m# initialize to unknown error\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmap:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;66;03m# sort tiles in file order\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Luan_van/source_code/Han_nom_NC_TT_HC_model1/.venv/lib/python3.9/site-packages/PIL/ImageFile.py:416\u001b[0m, in \u001b[0;36mImageFile.load_prepare\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_prepare\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;66;03m# create image memory if necessary\u001b[39;00m\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_im \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;66;03m# create palette (optional)\u001b[39;00m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ‚úÖ UPDATED: ƒê∆∞·ªùng d·∫´n ƒë·∫øn model checkpoint M·ªöI\n",
    "MODEL_PATH = \"models/conditional_model/1/best_model.pth\"  # Conditional model with rotation detection\n",
    "\n",
    "# Ch·∫°y evaluation\n",
    "# test_rotations=False: ch·ªâ test v·ªõi g√≥c xoay 0 ƒë·ªô (·∫£nh g·ªëc)\n",
    "# test_rotations=True: test v·ªõi c√°c g√≥c xoay 0, 90, 180, 270 ƒë·ªô\n",
    "evaluate_multi_task_model(\n",
    "    model_path=MODEL_PATH,\n",
    "    test_folder=TEST_PATH,\n",
    "    output_path=OUTPUT_PATH,\n",
    "    test_rotations=True  # ‚úÖ Enable rotation testing cho conditional model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bb494c",
   "metadata": {},
   "source": [
    "## üìù 6. Notes\n",
    "\n",
    "### C·∫•u tr√∫c test folder:\n",
    "```\n",
    "test_full/\n",
    "‚îú‚îÄ‚îÄ SinoNom/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Thong_thuong/\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Doc/\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Ngang/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Hanh_chinh/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ Ngoai_canh/\n",
    "‚îî‚îÄ‚îÄ NonSinoNom/\n",
    "```\n",
    "\n",
    "### Output files:\n",
    "- **Excel file**: Chi ti·∫øt k·∫øt qu·∫£ d·ª± ƒëo√°n cho t·ª´ng ·∫£nh v·ªõi thumbnail\n",
    "- **Confusion matrices**: Visualization c·ªßa confusion matrices cho t·∫•t c·∫£ c√°c tasks\n",
    "\n",
    "### Model tasks:\n",
    "1. **Main Category**: SinoNom vs NonSinoNom\n",
    "2. **Document Type**: Thong_thuong, Hanh_chinh, Ngoai_canh (ch·ªâ cho SinoNom)\n",
    "3. **Text Direction**: Doc, Ngang (ch·ªâ cho Thong_thuong)\n",
    "4. **Rotation**: 0¬∞, 90¬∞, 180¬∞, 270¬∞"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
